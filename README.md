# System-Design
            System Design Notes
1я╕ПтГг HLD (High-Level Design) vs LLD (Low-Level Design)
ЁЯФ╣ HLD (High-Level Design)
Definition (English): It shows the overall system architecture, main components, and how they interact.


ржмрж╛ржВрж▓рж╛рзЯ: ржкрзБрж░рзЛ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржмрзЬ ржЫржмрж┐/architecture ржмрзЛржЭрж╛рзЯред ржХрзЛржи ржХрзЛржи ржоржбрж┐ржЙрж▓ ржерж╛ржХржмрзЗ, рждрж╛рж░рж╛ ржХрж┐ржнрж╛ржмрзЗ connect рж╣ржмрзЗ рждрж╛ define ржХрж░рзЗред


ЁЯСЙ Features:
Big picture view of system


Technology stack, architecture (Monolithic / Microservices)


Modules and their relationships


Focus: What system will do


ЁЯСЙ Example:
 Banking system тЖТ Modules: Login, Accounts, Transactions, Reports.

ЁЯФ╣ LLD (Low-Level Design)
Definition (English): It gives detailed logic of each component/module.


ржмрж╛ржВрж▓рж╛рзЯ: ржкрзНрж░рждрж┐ржЯрж┐ ржоржбрж┐ржЙрж▓рзЗрж░ ржнрзЗрждрж░рзЗ ржХрзАржнрж╛ржмрзЗ ржХрж╛ржЬ рж╣ржмрзЗ рждрж╛ detail level ржП ржмрзЛржЭрж╛рзЯред


ЁЯСЙ Features:
Class diagrams, database schema


API design, function-level details


Algorithms and pseudo code


Focus: How system will work


ЁЯСЙ Example:
 Transaction Module тЖТ Functions: debitAccount(), creditAccount(), validation rules, DB tables.

2я╕ПтГг Functional vs Non-Functional Requirements
ЁЯФ╣ Functional Requirements
Definition (English): Features and functions the system must perform.


ржмрж╛ржВрж▓рж╛рзЯ: рж╕рж┐рж╕рзНржЯрзЗржо ржХрзА ржХрзА ржХрж╛ржЬ ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗ, рж╕рзЗржЗ ржлрж╛ржВрж╢ржи/ржлрж┐ржЪрж╛рж░ржЧрзБрж▓рзЛред


ЁЯСЙ Examples:
User login & signup


Payment processing


Search option


Upload documents



ЁЯФ╣ Non-Functional Requirements (NFR)
Definition (English): Quality attributes and constraints of the system.


ржмрж╛ржВрж▓рж╛рзЯ: рж╕рж┐рж╕рзНржЯрзЗржо ржХрждржЯрж╛ ржжрзНрж░рзБржд, рж╕рзБрж░ржХрзНрж╖рж┐ржд, reliable ржЗрждрзНржпрж╛ржжрж┐ред ржХрж╛ржЬрзЗрж░ ржмрж╛ржЗрж░рзЗ quality measureред


ЁЯСЙ Examples:
Performance тЖТ System must handle 10k users at once


Security тЖТ Data encryption, authentication


Scalability тЖТ Horizontal scaling support


Reliability тЖТ 99.9% uptime guarantee



ЁЯУЭ Quick Revision Table
Topic
Focus
Example
HLD
What system will do (Big picture)
Banking System Modules
LLD
How system will work (Details)
Functions, DB schema
Functional Req.
System features (DoтАЩs)
Login, Payment, Search
Non-Functional Req.
Quality attributes
Speed, Security, Uptime



ЁЯУМ Monolithic Architecture
ЁЯФ╣ Definition
English: Monolithic architecture is a single unified software system where all the components (UI, business logic, database, etc.) are tightly coupled and run as one unit.


ржмрж╛ржВрж▓рж╛рзЯ: Monolithic architecture рж╣рж▓рзЛ ржПржоржи ржПржХржЯрж┐ рж╕ржлржЯржУрзЯрзНржпрж╛рж░ ржбрж┐ржЬрж╛ржЗржи ржпрзЗржЦрж╛ржирзЗ рж╕ржмржХрж┐ржЫрзБ ржПржХрж╕рж╛ржерзЗ (ржПржХржЯрж╛ ржмрзНрж▓ржХрзЗрж░ ржорждрзЛ) рждрзИрж░рж┐ рж╣рзЯ тАФ ржпрзЗржоржи UI, business logic, database рж╕ржм ржПржХ ржЬрж╛рзЯржЧрж╛рзЯ ржерж╛ржХрзЗред



ЁЯФ╣ Characteristics (ржмрзИрж╢рж┐рж╖рзНржЯрзНржп)
Single codebase тЖТ ржкрзБрж░рзЛ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи ржПржХржЯрж╛ржЗ ржХрзЛржбржмрзЗрж╕рзЗ ржерж╛ржХрзЗред


Tightly coupled тЖТ рж╕ржм ржоржбрж┐ржЙрж▓ ржПржХрзЗ ржЕржкрж░рзЗрж░ рж╕рж╛ржерзЗ strongly connectedред


Single deployable unit тЖТ ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржиржХрзЗ ржЖрж▓рж╛ржжрж╛ ржЖрж▓рж╛ржжрж╛ ржХрж░рзЗ ржирзЯ, ржмрж░ржВ ржкрзБрж░рзЛржЯрж╛ ржПржХрж╕рж╛ржерзЗ deploy ржХрж░рждрзЗ рж╣рзЯред


Simple to develop initially тЖТ ржЫрзЛржЯ ржкрзНрж░ржЬрзЗржХрзНржЯрзЗ рж╕рж╣ржЬрзЗ рждрзИрж░рж┐ ржХрж░рж╛ ржпрж╛рзЯред



ЁЯФ╣ Advantages (рж╕рзБржмрж┐ржзрж╛)
тЬЕ Easy to develop for small apps
 тЬЕ Easy to test (unit test simple)
 тЬЕ Single deployment process
 тЬЕ Performance better (no network latency between services)

ЁЯФ╣ Disadvantages (ржЕрж╕рзБржмрж┐ржзрж╛)
тЭМ Large codebase тЖТ Hard to maintain
 тЭМ Scalability problem тЖТ ржкрзБрж░рзЛ ржЕрзНржпрж╛ржк scale ржХрж░рждрзЗ рж╣рзЯ, ржЖрж▓рж╛ржжрж╛ module ржирзЯ
 тЭМ Deployment risk тЖТ ржЫрзЛржЯ change ржХрж░рж▓рзЗржУ ржкрзБрж░рзЛ system redeploy ржХрж░рждрзЗ рж╣рзЯ
 тЭМ Technology lock-in тЖТ рж╕ржм ржоржбрж┐ржЙрж▓ same tech stack ржП ржерж╛ржХрждрзЗ рж╣рзЯ

ЁЯФ╣ Example
E-commerce Monolith App тЖТ Product management, user authentication, payment system рж╕ржм ржПржХ ржкрзНрж░ржЬрзЗржХрзНржЯрзЗ build ржХрж░рж╛ред


ржпржжрж┐ payment system-ржП bug рж╣рзЯ тЖТ ржкрзБрж░рзЛ app ржЖржмрж╛рж░ deploy ржХрж░рждрзЗ рж╣ржмрзЗред








Difference Between Monolithic and Microservices Architecture



ЁЯФ╣ Monolithic Architecture
Definition (English): Single unified application where all components (UI, business logic, DB) are tightly coupled.


ржмрж╛ржВрж▓рж╛рзЯ: рж╕ржм ржоржбрж┐ржЙрж▓/ржлрж┐ржЪрж╛рж░ ржПржХ ржХрзЛржбржмрзЗрж╕рзЗ ржерж╛ржХрзЗ, рж╕ржмржХрж┐ржЫрзБ ржПржХрж╕рж╛ржерзЗ deploy рж╣рзЯред


ЁЯСЙ Example: ржПржХржЯрж┐ e-commerce app ржпрзЗржЦрж╛ржирзЗ product, payment, user рж╕ржмржХрж┐ржЫрзБ ржПржХ project-ржПрж░ ржоржзрзНржпрзЗред
 Monolithic Architecture-ржП Latency
Monolithic-ржП:
рж╕ржм modules ржПржХржЗ process / server-ржП ржерж╛ржХрзЗред


Internal calls function calls ржПрж░ ржорж╛ржзрзНржпржорзЗ рж╣ржпрж╝ред


рждрж╛ржЗ communication ржЕржирзЗржХ ржжрзНрж░рзБржд рж╣ржпрж╝ред


ржЙржжрж╛рж╣рж░ржг:
 User requests тАЬPlace OrderтАЭ тЖТ Server internally function call ржжрж┐ржпрж╝рзЗ Payment + Inventory + Notification process ржХрж░рзЗ тЖТ Response ржЦрзБржм ржжрзНрж░рзБржд ржЖрж╕рзЗред
Latency Factor:
рж╕рж╛ржзрж╛рж░ржгржд low latency ржХрж╛рж░ржг internal calls network ржПрж░ ржоржзрзНржп ржжрж┐ржпрж╝рзЗ ржпрж╛ржпрж╝ ржирж╛ред


Bottleneck рж╢рзБржзрзБ server CPU/memoryред


тЬЕ ржлрж╛ржпрж╝ржжрж╛: Internal communication ржЕржирзЗржХ ржжрзНрж░рзБрждред
 тЭМ ржЕрж╕рзБржмрж┐ржзрж╛: ржЕрзНржпрж╛ржк ржмржбрж╝ рж╣рж▓рзЗ ржПржмржВ load ржмрзЗрж╢рж┐ рж╣рж▓рзЗ single server-ржП congestion рж╣рждрзЗ ржкрж╛рж░рзЗ тЖТ latency ржмрж╛ржбрж╝рзЗред


ЁЯФ╣ Microservices Architecture
Definition (English): Application is broken into small independent services, each running on its own and communicating via APIs.


ржмрж╛ржВрж▓рж╛рзЯ: ржмрзЬ ржЕрзНржпрж╛ржкржХрзЗ ржЫрзЛржЯ ржЫрзЛржЯ рж╕рж╛рж░рзНржнрж┐рж╕рзЗ ржнрж╛ржЧ ржХрж░рж╛ рж╣рзЯ, ржкрзНрж░рждрж┐ржЯрж┐ ржЖрж▓рж╛ржжрж╛ ржнрж╛ржмрзЗ deploy ржУ scale ржХрж░рж╛ ржпрж╛рзЯред
Microservices Architecture
тЬЕ Advantages
Scalability тЖТ Scale only the required service (e.g., Payment service)ред


Independent Deployment тЖТ ржПржХрзЗржХржЯрж╛ service ржЖрж▓рж╛ржжрж╛ deploy ржХрж░рж╛ ржпрж╛рзЯ, ржХржо riskред


Flexibility тЖТ ржкрзНрж░рждрж┐ржЯрж┐ рж╕рж╛рж░рзНржнрж┐рж╕рзЗ ржЖрж▓рж╛ржжрж╛ tech stack ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ ржпрж╛рзЯред


Fault Isolation тЖТ ржПржХ рж╕рж╛рж░рзНржнрж┐рж╕ down рж╣рж▓рзЗржУ ржкрзБрж░рзЛ system down рж╣рзЯ ржирж╛ред


Faster Development (Large Teams) тЖТ Multiple teams ржПржХрж╕рж╛ржерзЗ different services ржирж┐рзЯрзЗ ржХрж╛ржЬ ржХрж░рждрзЗ ржкрж╛рж░рзЗред


Better Maintainability тЖТ ржЫрзЛржЯ codebase рж╣ржУрзЯрж╛рзЯ рж╕рж╣ржЬрзЗ modify ржХрж░рж╛ ржпрж╛рзЯред


Cloud Friendly тЖТ Containerization (Docker, Kubernetes) ржПрж░ рж╕рж╛ржерзЗ ржнрж╛рж▓рзЛржнрж╛ржмрзЗ fit ржХрж░рзЗред


тЭМ Disadvantages
Complexity in Management тЖТ ржЕржирзЗржХ рж╕рж╛рж░рзНржнрж┐рж╕ deploy, monitor, manage ржХрж░рж╛ ржХржарж┐ржиред


Performance Overhead тЖТ API call/network latency ржмрзЗрж╢рж┐ред


Testing Difficulty тЖТ Integration testing harder due to many servicesред


DevOps Dependency тЖТ Automation, CI/CD pipeline, orchestration tools ржкрзНрж░рзЯрзЛржЬржиред


Data Management Issue тЖТ ржкрзНрж░рждрж┐ржЯрж┐ рж╕рж╛рж░рзНржнрж┐рж╕ ржЖрж▓рж╛ржжрж╛ database ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж▓рзЗ consistency maintain ржХрж░рж╛ ржХржарж┐ржиред


Skill Requirement тЖТ Developers & Ops team ржПрж░ ржмрзЗрж╢рж┐ ржЬрзНржЮрж╛ржи ржжрж░ржХрж╛рж░ (cloud, containers, orchestration)ред




ЁЯСЙ Example: E-commerce app тЖТ Payment service ржЖрж▓рж╛ржжрж╛, Product service ржЖрж▓рж╛ржжрж╛, User 
service ржЖрж▓рж╛ржжрж╛ред
Microservices-ржП Latency
Microservices-ржП:
ржкрзНрж░рждрж┐ржЯрж┐ module ржЖрж▓рж╛ржжрж╛ service рж╣рж┐рж╕рзЗржмрзЗ ржерж╛ржХрзЗред


Services ржПржХрзЗ ржЕржкрж░рзЗрж░ рж╕рж╛ржерзЗ network calls (HTTP/REST, gRPC, message queue) ржПрж░ ржорж╛ржзрзНржпржорзЗ communicate ржХрж░рзЗред


рждрж╛ржЗ communication slow рж╣ржпрж╝ред


ржЙржжрж╛рж╣рж░ржг:
 User requests тАЬPlace OrderтАЭ тЖТ Order Service тЖТ Payment Service тЖТ Inventory Service тЖТ Notification Service тЖТ Response
Latency Factor:
Network latency + serialization/deserialization + multiple service hops тЖТ ржорзЛржЯ latency Monolithic-ржПрж░ ржЪрзЗржпрж╝рзЗ ржмрзЗрж╢рж┐ред


ржкрзНрж░рждрж┐ржЯрж┐ service independent, рждрж╛ржЗ ржПржХ service crash ржХрж░рж▓рзЗ рж╕ржм system hang рж╣ржпрж╝ ржирж╛ред


тЬЕ ржлрж╛ржпрж╝ржжрж╛: Fault isolation, independent scalingред
 тЭМ ржЕрж╕рзБржмрж┐ржзрж╛: Network latency ржмрзЗрж╢рж┐ тЖТ response time ржзрзАрж░ред

тЪб рждрзБрж▓ржирж╛ржорзВрж▓ржХ (Latency)
Feature
Monolithic
Microservices
Internal Communication
Function call тЖТ very fast
Network call тЖТ slower
Average Latency
Low
Higher (depends on network & hops)
Scalability
Difficult
Easy (scale only needed services)
Fault Tolerance
Low
High


ЁЯТб рж╕рж╛рж░рж╛ржВрж╢:
Monolithic тЖТ low latency, ржХрж┐ржирзНрждрзБ scale/maintenance ржХржарж┐ржиред


Microservices тЖТ higher latency (network calls), ржХрж┐ржирзНрждрзБ scale, maintain ржУ fault tolerance ржЕржирзЗржХ ржнрж╛рж▓рзЛред


ЁЯУЭ Comparison Table
Feature
Monolithic
Microservices
Structure
Single codebase, tightly coupled
Multiple small services, loosely coupled
Deployment
Whole app deployed together
Each service deployed independently
Scalability
Hard (must scale entire app)
Easy (scale specific service only)
Technology Stack
Same tech for all modules
Different services can use different tech
Performance
Faster (no network calls between modules)
Slightly slower (services communicate via APIs)
Maintenance
Difficult when codebase grows
Easier, as services are smaller
Failure impact
One bug may crash whole system
Failure limited to single service
Best for
Small/medium apps
Large, complex, scalable apps






1я╕ПтГг What is Latency? (Latency ржХрзА?)

Latency ржорж╛ржирзЗ рж╣рж▓рзЛ network delay тАУ ржХрзЛржирзЛ data ржПржХржЯрж┐ point ржерзЗржХрзЗ ржЕржирзНржп point ржП ржкрзМржБржЫрж╛рждрзЗ ржХржд рж╕ржорзЯ рж▓рж╛ржЧрзЗред
Bangla-English:
 тАЬLatency рж╣рж▓рзЛ network-ржП data ржкрж╛ржарж╛ржирзЛрж░ рж╕ржоржпрж╝ред ржпржжрж┐ latency ржмрзЗрж╢рж┐ рж╣ржпрж╝, рждрж╛рж╣рж▓рзЗ network slow ржЕржирзБржнрзВржд рж╣ржпрж╝редтАЭ


Example:
ржзрж░рзЛ рждрзБржорж┐ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржерзЗржХрзЗ USA-ржПрж░ server-ржП request ржкрж╛ржарж╛рж▓рзЗ, рж╕рзЗржЗ request-ржПрж░ ржЙрждрзНрждрж░ ржЖрж╕рждрзЗ ржпрж╛ рж╕ржорзЯ рж▓рж╛ржЧрзЗтАФ рж╕рзЗржЯрж╛ржЗ latencyред


Measurement:
ржорж╛ржкрж╛ рж╣рзЯ milliseconds (ms) ржПред



2я╕ПтГг Types of Latency (Latency-ржПрж░ ржзрж░ржи)
Propagation latency:


Data signal ржХрждрзЛ ржжрзНрж░рзБржд network medium (cable, fiber, wireless) ржжрж┐ржпрж╝рзЗ travel ржХрж░ржЫрзЗред


Transmission latency:


Data send ржХрж░рждрзЗ ржХржд рж╕ржорзЯ рж▓рж╛ржЧрзЗ (data size ржПржмржВ bandwidth ржПрж░ ржЙржкрж░ ржирж┐рж░рзНржнрж░ ржХрж░рзЗ)


Processing latency:


Router, switch ржмрж╛ server data process ржХрж░рждрзЗ ржХржд рж╕ржорзЯ ржирж┐ржЪрзНржЫрзЗ


Queuing latency:


Network ржП traffic congestion рж╣рж▓рзЗ waiting time ржмрзГржжрзНржзрж┐ ржкрж╛ржпрж╝





3я╕ПтГг How to Reduce Latency (Latency ржХржорж╛ржирзЛрж░ ржЙржкрж╛рзЯ)
Bangla-English tips:


Use a CDN (Content Delivery Network)


Data user-ржПрж░ ржХрж╛ржЫрж╛ржХрж╛ржЫрж┐ server ржерзЗржХрзЗ provide ржХрж░рж╛ рж╣рзЯ тЖТ distance ржХржорзЗ latency ржХржорзЗ


Caching


Frequently accessed data local server ржмрж╛ browser-ржП рж░рж╛ржЦрж▓рзЗ server request ржХржо рж╣рзЯ тЖТ latency ржХржорзЗ


Optimize network path


Direct routes use ржХрж░рж╛, unnecessary hops ржХржорж╛ржирзЛ


Upgrade bandwidth


Bigger bandwidth тЖТ transmission latency ржХржо рж╣рзЯ


Use faster servers / edge servers


Processing latency ржХржорж╛ржирзЛ ржпрж╛рзЯ



4я╕ПтГг CDN vs Caching (Bangla-English)
Feature
CDN (Content Delivery Network)
Caching
Purpose
User-ржПрж░ ржХрж╛ржЫрзЗ content provide ржХрж░рж╛
Frequently used data store ржХрж░рж╛
Location
Multiple global edge servers
Local server/browser
Example
Akamai, Cloudflare, AWS CloudFront
Browser cache, Redis, Memcached
Latency Impact
Reduce distance-based latency
Reduce server processing latency
Use Case
Static content like images, videos
Dynamic/static data for fast access

Bangla-English summary:
CDN = global scale latency reduce



Caching = server load ржХржорж┐рзЯрзЗ latency reduce







Throughput in System Design

Definition:
 Throughput рж╣рж▓рзЛ ржПржХржЯрж┐ system ржХржд efficiently ржХрж╛ржЬ ржХрж░ржЫрзЗ ржмрж╛ ржХржд request/process/unit time ржП complete ржХрж░рждрзЗ ржкрж╛рж░ржЫрзЗред
рж╕рж╣ржЬржнрж╛ржмрзЗ ржмрж▓рж▓рзЗ: тАЬржПржХржЯрж╛ system ржХржд request/transaction/operation per second handle ржХрж░рждрзЗ ржкрж╛рж░рзЗредтАЭ


Unit: requests/sec, transactions/sec, operations/sec



Example (Bangla + English)
Scenario:
 ржзрж░рж╛ ржпрж╛ржХ, рждрзБржорж┐ ржПржХржЯрж╛ online shopping website ржмрж╛ржирж╛ржЪрзНржЫред
System Input: Users sending requests to view products, place orders, etc.


Throughput: ржпржжрж┐ system ржПржХ second-ржП 1000 requests successfully process ржХрж░рждрзЗ ржкрж╛рж░рзЗ, рждрж╛рж╣рж▓рзЗ system-ржПрж░ throughput = 1000 requests/secред


Latency vs Throughput:


Latency = ржХржд time рж▓рж╛ржЧрзЗ ржПржХ individual request complete ржХрж░рждрзЗред


Throughput = ржХржд request system ржПржХ unit time-ржП handle ржХрж░рждрзЗ ржкрж╛рж░рзЗред


Bangla Example:
ржзрж░рзЛ, Amazon website-ржП 1 ржорж┐ржирж┐ржЯрзЗ 60,000 order request ржЖрж╕рзЗред


ржпржжрж┐ system 1 ржорж┐ржирж┐ржЯрзЗ рж╕ржм 60,000 request successfully process ржХрж░рзЗ тЖТ throughput = 1,000 requests/secред



Key Points for System Design
High throughput тЖТ System can handle more requests per second.


Throughput can be increased by:


Horizontal scaling (more servers)


Load balancing


Caching frequent data


Database optimization


Trade-off: High throughput system may have higher latency per request if resources are stretched.
How to Improve Throughput
1. Horizontal Scaling (Scale Out)
Explanation: ржПржХрзЗрж░ ржмрзЗрж╢рж┐ server/instance ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ред


Bangla Example: ржпржжрж┐ рждрзЛржорж╛рж░ website ржПржХ server-ржП 1000 request/sec handle ржХрж░рзЗ, ржжрзБржЗ server ржП handle рж╣ржмрзЗ ~2000 request/secред


Method: Use load balancers to distribute traffic.



2. Vertical Scaling (Scale Up)
Explanation: Existing server-ржПрж░ resource (CPU, RAM, Network) ржмрж╛рзЬрж╛ржирзЛред


Example: ржПржХржЯрж┐ powerful CPU + ржмрзЗрж╢рж┐ RAM тЖТ ржмрзЗрж╢рж┐ requests ржПржХржЗ server-ржП handle ржХрж░рж╛ рж╕ржорзНржнржмред



3. Caching
Explanation: Frequently used data memory ржмрж╛ cache-ржП рж░рж╛ржЦрж╛ ржпрж╛рждрзЗ database access ржХржо рж▓рж╛ржЧрзЗред


Bangla Example: Product info cache-ржП рж░рж╛ржЦрж▓рзЗ, user request handle ржХрж░рж╛рж░ ржЬржирзНржп database query ржХрж░рж╛рж░ ржкрзНрж░рзЯрзЛржЬржи ржкрзЬрзЗ ржирж╛ тЖТ faster processing тЖТ higher throughput.


Tools: Redis, Memcached



4. Database Optimization
Explanation: Efficient queries, indexing, read replicas.


Bangla Example: Large table scan ржХрж░рзЗ data fetch ржХрж░рж▓рзЗ slow рж╣ржмрзЗ тЖТ indexing ржХрж░рж▓рзЗ request fast рж╣ржмрзЗ тЖТ throughput ржмрж╛рзЬржмрзЗред


Tips: Use sharding, partitioning, or read replicas for high read load.



5. Asynchronous Processing
Explanation: ржХрж┐ржЫрзБ task background-ржП ржХрж░рж╛, main request fast handle ржХрж░рж╛ред


Example:


User places order тЖТ enqueue task for email notification тЖТ user doesnтАЩt wait тЖТ throughput increases.


Tools: RabbitMQ, Kafka, Celery



6. Reduce Bottlenecks
Identify slow components (CPU, DB, network) and optimize.


Example: If payment processing is slow тЖТ use payment gateways asynchronously or batch processing.



7. Optimize Network / API Calls
Minimize data transfer and API latency.


Example: Compress responses, batch multiple requests тЖТ faster handling тЖТ higher throughput.



ЁЯТб Quick Tip:
Latency and throughput are related but different. Sometimes reducing latency improves throughput, but sometimes increasing parallelism improves throughput without affecting latency too much.
Advantages of High Throughput in System Design
1. Better User Experience (ржмрзЗрж╢рж┐ Smooth & Fast)
High throughput means system can handle more requests quickly тЖТ users donтАЩt face delays or timeouts.


Example: Online shopping website can handle thousands of users at the same time without slowing down.



2. Scalability (Scale ржХрж░рждрзЗ рж╕рж╣ржЬ)
Throughput optimization techniques (horizontal scaling, caching, async processing) help system scale easily for more users.


Example: During festive sales, system can handle spike in traffic without crashing.



3. Cost Efficiency (ржХржо ржЦрж░ржЪрзЗ ржмрзЗрж╢рж┐ ржХрж╛ржЬ)
Optimized throughput reduces resource wastage.


Example: Efficient DB queries & caching тЖТ fewer servers needed тЖТ cost saves money.



4. Reliability (More Reliable System)
System with high throughput can handle heavy loads without failing.


Example: Even if 10,000 requests come simultaneously, system processes all without downtime.



5. Competitive Advantage
A fast, high-throughput system retains more users and customers.


Example: Fast-loading app тЖТ users stay тЖТ business grows.



6. Better Resource Utilization
System processes more tasks per second тЖТ CPU, memory, network used efficiently.



ЁЯТб Summary:
 High throughput = fast, reliable, scalable, cost-efficient system. ItтАЩs critical for websites, APIs, databases, microservices and almost all modern systems.

Availability (Bangla + English Notes)
ЁЯФ╣ What is Availability?


English:
 Availability refers to how much a system is operational and accessible when needed. It is usually measured as a percentage of uptime (e.g., 99.9% availability).
Bangla:
 Availability ржорж╛ржирзЗ рж╣рж▓рзЛ, ржПржХржЯрж╛ рж╕рж┐рж╕рзНржЯрзЗржо ржХрждржХрзНрж╖ржг рж╕ржЪрж▓ ржУ ржмрзНржпржмрж╣рж╛рж░ржпрзЛржЧрзНржп ржерж╛ржХрзЗред рж╕рж╛ржзрж╛рж░ржгржд ржПржЯрж┐ uptime рж╢рждрж╛ржВрж╢ ржжрж┐рзЯрзЗ ржкрзНрж░ржХрж╛рж╢ ржХрж░рж╛ рж╣рзЯ (ржпрзЗржоржи: 99.9% availability)ред
Formula (Approx):
Availability=UptimeUptime+DowntimeAvailability = \frac{Uptime}{Uptime + Downtime}Availability=Uptime+DowntimeUptimeтАЛ
ЁЯФ╣ Replication
English:
 Replication means copying data or services across multiple servers or locations. If one server fails, another copy can serve the request.
Example: Database replication (Master тЖТ Slave).


Goal: Improve read performance & availability.


Problem: Data consistency issues (may lag).


Bangla:
 Replication ржорж╛ржирзЗ рж╣рж▓рзЛ ржПржХржЗ ржбрзЗржЯрж╛ ржмрж╛ рж╕рж╛рж░рзНржнрж┐рж╕ ржПржХрж╛ржзрж┐ржХ рж╕рж╛рж░рзНржнрж╛рж░рзЗ ржХржкрж┐ ржХрж░рзЗ рж░рж╛ржЦрж╛ред ржпржжрж┐ ржПржХржЯрж┐ рж╕рж╛рж░рзНржнрж╛рж░ ржирж╖рзНржЯ рж╣рзЯ, ржЕржирзНржп рж╕рж╛рж░рзНржнрж╛рж░ ржерзЗржХрзЗ рж╕рж╛рж░рзНржнрж┐рж╕ ржЪрж╛рж▓рзБ ржерж╛ржХрзЗред
ржЙржжрж╛рж╣рж░ржг: Database replication (Master тЖТ Slave)ред


ржорзВрж▓ ржЙржжрзНржжрзЗрж╢рзНржп: read performance ржУ availability ржмрж╛рзЬрж╛ржирзЛред


рж╕ржорж╕рзНржпрж╛: ржбрзЗржЯрж╛ consistent ржирж╛ ржерж╛ржХрж╛рж░ ржЭрзБржБржХрж┐ ржерж╛ржХрзЗ (delay рж╣рждрзЗ ржкрж╛рж░рзЗ)ред



ЁЯФ╣ Redundancy
English:
 Redundancy means having extra hardware, software, or systems as backup to ensure no single point of failure.
Example: Two power supplies in a server, RAID disks.


Goal: Improve fault tolerance & high availability.


Problem: Expensive, needs proper failover mechanism.


Bangla:
 Redundancy ржорж╛ржирзЗ рж╣рж▓рзЛ ржЕрждрж┐рж░рж┐ржХрзНржд рж░рж┐рж╕рзЛрж░рзНрж╕ рж░рж╛ржЦрж╛ (рж╣рж╛рж░рзНржбржУрзЯрзНржпрж╛рж░, рж╕ржлржЯржУрзЯрзНржпрж╛рж░, ржирзЗржЯржУрзЯрж╛рж░рзНржХ) ржпрж╛рждрзЗ ржХрзЛржирзЛ ржПржХржЯрж┐рждрзЗ рж╕ржорж╕рзНржпрж╛ рж╣рж▓рзЗ ржкрзБрж░рзЛ рж╕рж┐рж╕рзНржЯрзЗржо ржмржирзНржз ржирж╛ рж╣рзЯрзЗ ржпрж╛рзЯред
ржЙржжрж╛рж╣рж░ржг: Server ржП рзиржЯрж╛ ржкрж╛ржУрзЯрж╛рж░ рж╕рж╛ржкрзНрж▓рж╛ржЗ, RAID ржбрж┐рж╕рзНржХред


ржорзВрж▓ ржЙржжрзНржжрзЗрж╢рзНржп: fault tolerance ржУ high availability ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рж╛ред


рж╕ржорж╕рзНржпрж╛: ржЦрж░ржЪ ржмрзЗрж╢рж┐ ржПржмржВ рж╕ржарж┐ржХ failover ржорзЗржХрж╛ржирж┐ржЬржо рж▓рж╛ржЧржмрзЗред



ЁЯФ╣ Replication vs Redundancy (Comparison Table)
Feature
Replication
Redundancy
Definition
Copy of data/services across servers
Extra backup hardware/system
Focus
Data & performance
Fault tolerance & reliability
Example
Database replication, CDN
RAID, multiple servers, backup power
Problem
Data inconsistency
Costly implementation
Availability Impact
Improves read availability & scalability
Ensures system continues even if part fails


ЁЯФ╣ Summary (Bangla + English Mix)
ЁЯСЙ Availability = System ржХрждржХрзНрж╖ржг рж╕ржЪрж▓ ржерж╛ржХрзЗред
 ЁЯСЙ Replication = Data/Service multiple copies тЖТ ржмрзЗрж╢рж┐ availability & read performance, but consistency problemред
 ЁЯСЙ Redundancy = Backup system/hardware тЖТ ржмрзЗрж╢рж┐ fault tolerance & high availability, but expensiveред

Availability in Monolithic vs Microservices (Replication vs Redundancy)
ЁЯФ╣ Monolithic System
English:
A monolithic system is one large codebase and tightly coupled.


Replication here usually means replicating the whole application in multiple servers.


Redundancy means having backup servers, load balancers, database failover.


Availability Impact:
Replication: Improves performance but scaling is limited (you have to replicate the entire app).


Redundancy: If one server crashes, backup can take over, but single point of failure (database, shared state) still exists.


Bangla:
Monolithic system рж╣рж▓рзЛ ржПржХржЯрж╛ ржмрзЬ ржХрзЛржбржмрзЗрж╕ ржпрзЗржЦрж╛ржирзЗ рж╕ржм ржоржбрж┐ржЙрж▓ ржПржХрж╕рж╛ржерзЗ ржерж╛ржХрзЗред


Replication ржорж╛ржирзЗ ржкрзБрж░рзЛ application ржПрж░ ржХржкрж┐ ржХрж░рзЗ ржПржХрж╛ржзрж┐ржХ рж╕рж╛рж░рзНржнрж╛рж░рзЗ ржЪрж╛рж▓рж╛ржирзЛред


Redundancy ржорж╛ржирзЗ backup server, load balancer, database failover ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ред


тЮбя╕П Availability:
Replication ржП performance ржХрж┐ржЫрзБржЯрж╛ ржмрж╛рзЬрзЗ ржХрж┐ржирзНрждрзБ ржкрзБрж░рзЛ app replicate ржХрж░рждрзЗ рж╣рзЯ, flexible ржирзЯред


Redundancy ржерж╛ржХрж▓рзЗржУ database ржмрж╛ ржЕржирзНржп dependency fail рж╣рж▓рзЗ рж╕рж┐рж╕рзНржЯрзЗржо ржкрзБрж░рзЛржкрзБрж░рж┐ down рж╣рзЯрзЗ ржпрзЗрждрзЗ ржкрж╛рж░рзЗред



ЁЯФ╣ Microservices System
English:
A microservices system splits the app into independent services (Auth, Payment, Orders, etc.).


Replication happens per service (e.g., 3 replicas of Payment service only).


Redundancy ensures each service has multiple instances, databases are sharded/replicated.


Availability Impact:
Replication: Much more efficient, only critical services are replicated.


Redundancy: No single point of failure, because even if one service instance dies, others keep running.


Bangla:
Microservices system ржП application ржХрзЗ ржЫрзЛржЯ ржЫрзЛржЯ рж╕рзНржмрж╛ржзрзАржи рж╕рж╛рж░рзНржнрж┐рж╕рзЗ ржнрж╛ржЧ ржХрж░рж╛ рж╣рзЯ (ржпрзЗржоржи: Auth, Payment, Orders)ред


Replication ржорж╛ржирзЗ ржкрзНрж░рзЯрзЛржЬржирзАрзЯ рж╕рж╛рж░рзНржнрж┐рж╕ржЧрзБрж▓рзЛ ржЖрж▓рж╛ржжрж╛ ржХрж░рзЗ replicate ржХрж░рж╛ ржпрж╛рзЯ (ржпрзЗржоржи рж╢рзБржзрзБ Payment service ржПрж░ рзйржЯрж╛ ржХржкрж┐ рж░рж╛ржЦрж╛)ред


Redundancy ржорж╛ржирзЗ ржкрзНрж░рждрж┐ржЯрж┐ рж╕рж╛рж░рзНржнрж┐рж╕рзЗрж░ backup instance ржерж╛ржХрзЗ, database ржЖрж▓рж╛ржжрж╛ shard/replica ржЖржХрж╛рж░рзЗ рж░рж╛ржЦрж╛ рж╣рзЯред


тЮбя╕П Availability:
Replication ржП targeted scalability ржкрж╛ржУрзЯрж╛ ржпрж╛рзЯ (critical service ржмрзЗрж╢рж┐ replicate ржХрж░рж╛ ржпрж╛рзЯ)ред


Redundancy ржП ржХрзЛржирзЛ single point of failure ржерж╛ржХрзЗ ржирж╛ред ржПржХ рж╕рж╛рж░рзНржнрж┐рж╕ down рж╣рж▓рзЗржУ ржмрж╛ржХрж┐ system ржЪрж▓рждрзЗ ржкрж╛рж░рзЗред



ЁЯФ╣ Comparison Table
Aspect
Monolithic
Microservices
Replication
Whole app replicated тЖТ heavy
Per-service replication тЖТ efficient
Redundancy
Backup servers, but still single DB failure risk
Each service + DB has redundancy тЖТ no single point of failure
Availability
Limited, database often bottleneck
Higher, resilient & fault tolerant
Scalability
Scale entire app only
Scale specific services independently


тЬЕ Summary:
Monolithic + Replication/Redundancy = availability improves a bit, but bottlenecks remain (DB, app size).


Microservices + Replication/Redundancy = high availability, because system is distributed, fault-tolerant, and scalable.


ЁЯФ╣ What is CAP Theorem?
CAP theorem (by Eric Brewer) says:
 In a Distributed System, you can only guarantee two out of the three properties:
C = Consistency


Every node sees the same data at the same time.


Example: ржпржжрж┐ рждрзБржорж┐ ржПржХржЯрж╛ ржбрзЗржЯрж╛ржмрзЗрж╕рзЗ update ржХрж░рзЛ, рж╕ржм server/user рж╕рзЗржЗ updated data ржПржХржЗ рж╕ржорзЯрзЗ ржкрж╛ржмрзЗред


A = Availability


The system always responds (even if some part fails).


Example: Server down рж╣рж▓рзЗржУ ржЕржирзНржп server ржерзЗржХрзЗ рждрзЛржорж╛рж░ query-ржПрж░ ржЙрждрзНрждрж░ ржкрж╛ржмрзЗред


P = Partition Tolerance


System continues working even if communication between nodes breaks (network failure)ред


ЁЯСЙ CAP theorem: In distributed systems, you can only pick 2 (CA, CP, AP) but not all 3 fully.

ЁЯФ╣ Examples in Bangla-English
1. CA System (Consistency + Availability, no Partition Tolerance)
Works fine when no network partition.


Example: Traditional SQL database on a single server.


Consistency ржЖржЫрзЗ (data рж╕ржмрж╕ржорзЯ correct),


Availability ржЖржЫрзЗ (server up ржерж╛ржХрж▓рзЗ рж╕ржмрж╕ржорзЯ response ржжрж┐ржмрзЗ),


But ржпржжрж┐ server fail ржХрж░рзЗ ржмрж╛ network partition рж╣рзЯ тЖТ ржкрзБрж░рзЛ рж╕рж┐рж╕рзНржЯрзЗржо down.



2. CP System (Consistency + Partition Tolerance, no Availability)
System prefers correctness over availability.


Example: MongoDB, HBase (in strict consistency mode)


ржпржжрж┐ network issue рж╣рзЯ, system data consistent рж░рж╛ржЦрзЗ, ржХрж┐ржирзНрждрзБ ржХрж┐ржЫрзБ рж╕ржорзЯрзЗрж░ ржЬржирзНржп unavailable рж╣рждрзЗ ржкрж╛рж░рзЗред


ржпрзЗржоржи ржмрзНржпрж╛ржВржХрзЗрж░ transaction system тАФ better to block request than give wrong balanceред



3. AP System (Availability + Partition Tolerance, no Consistency)
System always responds, even if not fully consistent.


Example: Cassandra, DynamoDB


Network problem рж╣рж▓рзЗржУ response ржжрж┐ржмрзЗ, ржХрж┐ржирзНрждрзБ ржХрж┐ржЫрзБ data eventually consistent рж╣ржмрзЗред


ржпрзЗржоржи: Facebook post like count тАУ ржПржХрж╕рж╛ржерзЗ рж╕ржм user ржПрж░ ржХрж╛ржЫрзЗ ржПржХ timing ржП update ржирж╛ржУ рж╣рждрзЗ ржкрж╛рж░рзЗ, ржХрж┐ржирзНрждрзБ later ржарж┐ржХ рж╣рзЯрзЗ ржпрж╛ржмрзЗред



ЁЯФ╣ ржмрж╛ржВрж▓рж╛ Example (Daily Life)
ржзрж░рж╛ ржпрж╛ржХ рждрзБржорж┐ ржЖрж░ рждрзЛржорж╛рж░ friend ржПржХржЗ Google Doc edit ржХрж░ржЫрзЛ:
ржпржжрж┐ рж╕ржмрж╕ржорзЯ same content ржжрзЗржЦрж╛ржУ (Consistency) + server рж╕ржмрж╕ржорзЯ online ржерж╛ржХрзЗ (Availability), рждржЦржи network problem рж╣рж▓рзЗ (Partition) ржХрж╛ржЬ ржХрж░ржмрзЗ ржирж╛ тЖТ CA.


ржпржжрж┐ рждрзЛржорж╛рж░ net problem рж╣рзЯ, system рж╣рзЯрждрзЛ рждрзЛржорж╛рж░ access block ржХрж░ржмрзЗ data loss ржПрзЬрж╛рждрзЗ тЖТ CP.


ржпржжрж┐ рждрзЛржорж╛рж░ net problem рж╣рзЯ, рждрж╛ржУ рждрзБржорж┐ edit ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗ ржХрж┐ржирзНрждрзБ ржкрж░рзЗ sync рж╣ржмрзЗ (eventual consistency) тЖТ AP.



ЁЯСЙ In System Design Interviews, рждрзБржорж┐ ржмрж▓рждрзЗ ржкрж╛рж░рзЛ:
Banking system prefers CP (Consistency over Availability).


Social media (Facebook, Twitter) prefers AP (Availability over strict Consistency).


Small single-server apps are CA.





ЁЯУМ Lamport Logical Clock (Simple Notes)

Distributed system-ржП ржПржХржЯрж╛ржЗ global ржШрзЬрж┐ (clock) ржирзЗржЗред


рждрж╛ржЗ event ржХрзЛржиржЯрж╛ ржЖржЧрзЗ/ржкрж░рзЗ ржШржЯрж▓рзЛ рждрж╛ ржмрзБржЭрждрзЗ Lamport Clock ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯред


ржкрзНрж░рждрж┐ржЯрж┐ process (P1, P2, тАж) ржирж┐ржЬрзЗрж░ ржПржХржЯрж╛ counter (LC) рж░рж╛ржЦрзЗред



ЁЯФ╣ Rules (Bangla-English mix)
Internal Event тЖТ LC = LC + 1


Send Message тЖТ LC = LC + 1, message ржПрж░ рж╕рж╛ржерзЗ LC attach ржХрж░рзЗ ржкрж╛ржарж╛ржмрзЗ


Receive Message тЖТ LC = max(own LC, received LC) + 1



ЁЯУЦ рж╕рзБржирзНржжрж░ Example
ржзрж░рж╛ ржпрж╛ржХ ржжрзБржЗржЯрж╛ process ржЖржЫрзЗ: P1 ржЖрж░ P2
ЁЯСЙ рж╢рзБрж░рзБрждрзЗ:
LC1 = 0


LC2 = 0



тЬЕ Step 1 тАУ Internal Event (P1)
P1 ржХрж┐ржЫрзБ ржХрж╛ржЬ ржХрж░рж▓рзЛ (ржпрзЗржоржи calculation ржХрж░рж▓рзЛ)


Rule: LC = LC + 1


LC1 = 1



тЬЕ Step 2 тАУ P1 sends message to P2
Message ржП attach ржХрж░рж╛ рж╣рж▓рзЛ timestamp = 1


ржПржЦржи message ржпрж╛ржЪрзНржЫрзЗ P2 ржПрж░ ржХрж╛ржЫрзЗ



тЬЕ Step 3 тАУ P2 receives message
Current LC2 = 0


Rule: LC2 = max(LC2, received TS) + 1


LC2 = max(0, 1) + 1 = 2


So, P2 ржЬрж╛ржирж▓рзЛ тЖТ P1 ржПрж░ event ржЖржЧрзЗ рж╣рзЯрзЗржЫрзЗ



тЬЕ Step 4 тАУ Internal Event (P2)
P2 ржирж┐ржЬрзЗ ржХрж┐ржЫрзБ event ржХрж░рж▓рзЛ


LC2 = 2 + 1 = 3



ЁЯСЙ Final Timestamps:
P1 event: LC1 = 1


Message send: LC1 = 1


P2 received: LC2 = 2


P2 internal event: LC2 = 3


ржПржЦржи clear ржмрзЛржЭрж╛ ржпрж╛ржЪрзНржЫрзЗ ржХрзЗ ржЖржЧрзЗ рж╣рзЯрзЗржЫрзЗ ржЖрж░ ржХрзЗ ржкрж░рзЗред

ЁЯОп Key Idea
If LC(a) < LC(b) тЖТ a happened before b


If LC(a) = LC(b) тЖТ a and b are concurrent (simultaneous but independent)



ЁЯФ╣ Real-Life Analogy (Bangla Example)
ржнрж╛ржмрзЛ ржжрзБржЗржЬржи student ржЖржЫрзЗ тАУ рждрзБржорж┐ ржЖрж░ рждрзЛржорж╛рж░ friendред
ржпржЦржи рждрзБржорж┐ notebook ржП рж▓рж┐ржЦрзЛ, page number рзз ржмрж╛рзЬрж╛ржУред


ржпржЦржи рждрзБржорж┐ message ржкрж╛ржарж╛ржУ, page number рж▓рж┐ржЦрзЗ ржкрж╛ржарж╛ржУред


Friend message ржкрзЗрж▓рзЗ ржжрзЗржЦрзЗ:

 new page = max(own page, received page) + 1


ЁЯСЙ ржПржнрж╛ржмрзЗ ржжрзБржЗржЬржирзЗрж░ рж▓рзЗржЦрж╛ ржЖрж▓рж╛ржжрж╛ notebook ржП рж╣рж▓рзЗржУ event ржПрж░ order maintain рж╣рзЯред

ЁЯУМ рждрж╛ржЗ Lamport Clock рж╕ржмрж╕ржорзЯ ржмрж▓рзЗ ржжрзЗрзЯ тАУ ржХрзЗ ржЖржЧрзЗ ржШржЯрж▓рзЛ, ржХрзЗ ржкрж░рзЗ ржШржЯрж▓рзЛ (causal order)ред


ЁЯУМ Scaling in System Design
Scaling ржорж╛ржирзЗ рж╣рж▓рзЛ тАУ system-ржХрзЗ ржмрзЗрж╢рж┐ load handle ржХрж░рж╛рж░ ржорждрзЛ capable ржХрж░рж╛ред
 ржПржЗ ржХрж╛ржЬржЯрж╛ ржХрж░рж╛рж░ ржжрзБржЗржЯрж╛ ржкржжрзНржзрждрж┐ ржЖржЫрзЗ:
Vertical Scaling (Scale Up)


Horizontal Scaling (Scale Out)


ЁЯФ╣ Vertical Scaling (Scale Up)
ржПржХржЯрж╛ржЗ server (ржмрж╛ machine)-ржП ржмрзЗрж╢рж┐ power ржпрзЛржЧ ржХрж░рж╛ред


ржпрзЗржоржи: RAM ржмрж╛рзЬрж╛ржирзЛ, faster CPU ржжрзЗрзЯрж╛, bigger SSD ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ред


Concept: тАЬMake one machine strongerтАЭ


тЬЕ Advantages:
Simple to implement


No code change needed


Consistency easy (single machine)


тЭМ Disadvantages:
Limited by hardware capacity (ржПржХржЯрж╛ server ржХржд RAM/CPU ржкрж░рзНржпржирзНржд ржирж┐рждрзЗ ржкрж╛рж░ржмрзЗ рждрж╛рж░ limit ржЖржЫрзЗ)


Expensive hardware рж▓рж╛ржЧрзЗ


Single point of failure (ржпржжрж┐ ржПржХ server down рж╣рзЯ тЖТ ржкрзБрж░рзЛ system down)


ЁЯСЙ Example:
Small website MySQL database тЖТ ржПржХржЯрж╛ржХрзЗ powerful machine-ржП ржЪрж╛рж▓рж╛ржирзЛред



ЁЯФ╣ Horizontal Scaling (Scale Out)
ржПржХрж╛ржзрж┐ржХ server ржпрзЛржЧ ржХрж░рж╛ ржПржмржВ load distribute ржХрж░рж╛ред


Concept: тАЬAdd more machines instead of making one strongerтАЭ


тЬЕ Advantages:
Scalability ржЦрзБржм ржмрзЗрж╢рж┐ (new machine add ржХрж░рж▓рзЗ capacity ржмрж╛рзЬржмрзЗ)


Fault tolerance ржнрж╛рж▓рзЛ (ржПржХ server down рж╣рж▓рзЗржУ ржЕржирзНржп server ржХрж╛ржЬ ржЪрж╛рж▓рж╛рждрзЗ ржкрж╛рж░ржмрзЗ)


Cheaper hardware ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ ржпрж╛рзЯ


тЭМ Disadvantages:
System design complex рж╣рзЯрзЗ ржпрж╛рзЯ (Load balancer, data replication, consistency manage ржХрж░рждрзЗ рж╣рзЯ)


Application ржХрзЗ distributed architecture ржЕржирзБржпрж╛рзЯрзА design ржХрж░рждрзЗ рж╣рзЯ


ЁЯСЙ Example:
Google, Facebook тЖТ millions of servers handle ржХрж░рзЗ horizontally


Cassandra / DynamoDB тЖТ horizontally scalable database



ЁЯУЦ Bangla-English Daily Life Analogy
ЁЯСЙ Vertical Scaling (Scale Up)
 ржПржХржЯрж╛ rickshaw-рждрзЗ рзк ржЬржи ржмрж╕рждрзЗ ржкрж╛рж░рзЗред рждрзБржорж┐ ржЪрж╛ржЗрж▓рзЗ ржПржЯрж╛ржХрзЗ truck ржмрж╛ржирж┐рзЯрзЗ рзирзж ржЬржи ржмрж╕рж╛рждрзЗ ржкрж╛рж░ржмрзЗред ржХрж┐ржирзНрждрзБ truck-ржПрж░ржУ ржПржХржЯрж╛ limit ржЖржЫрзЗ (ржПржХрж╕ржорзЯ ржЖрж░ upgrade ржХрж░рж╛ ржпрж╛ржмрзЗ ржирж╛)ред
ЁЯСЙ Horizontal Scaling (Scale Out)
 ржПржХржЯрж╛ truck-ржПрж░ capacity ржмрж╛рзЬрж╛ржирзЛрж░ ржмржжрж▓рзЗ рждрзБржорж┐ ржЖрж░ржУ truck ржХрж┐ржирзЗ ржлрзЗрж▓рзЛред рждржЦржи ржпржд ржжрж░ржХрж╛рж░ рждржд truck ржпрзЛржЧ ржХрж░рж╛ ржпрж╛ржмрзЗред

ЁЯОп Quick Comparison Table
Feature
Vertical Scaling (Up)
Horizontal Scaling (Out)
Method
Stronger machine
More machines
Cost
Expensive hardware
Commodity servers
Limit
Hardware рж╕рзАржорж┐ржд
Practically unlimited
Complexity
Simple
Complex (distributed)
Failure impact
Single point of failure
More fault tolerant
Example
Add more RAM/CPU
Add more servers (cluster)


ЁЯСЙ Interview-ржП answer ржжрж┐рждрзЗ ржкрж╛рж░рзЛ ржПржнрж╛ржмрзЗ:
Vertical Scaling = ржПржХржЯрж╛ржХрзЗ powerful ржХрж░рж╛ (limited, simple)


Horizontal Scaling = ржЕржирзЗржХржЧрзБрж▓рзЛ server add ржХрж░рж╛ (scalable, complex)





Redundancy ржЖрж░ Replication ржПрж░ ржоржзрзНржпрзЗ ржкрж╛рж░рзНржержХрзНржп


 Redundancy (рж░рж┐ржбрж╛ржирзНржбрзЗржирзНрж╕рж┐)
English:
 Redundancy means having extra (backup) components in a system so that if one fails, another can take over. It is about fault tolerance and ensuring system availability.
Bangla:
 Redundancy ржорж╛ржирзЗ рж╣рж▓рзЛ рж╕рж┐рж╕рзНржЯрзЗржорзЗ ржЕрждрж┐рж░рж┐ржХрзНржд (backup) ржЬрж┐ржирж┐рж╕ рж░рж╛ржЦрж╛, ржпрж╛рждрзЗ ржПржХржЯрж┐ ржирж╖рзНржЯ рж╣рж▓рзЗржУ ржЕржирзНржпржЯрж┐ ржХрж╛ржЬ ржЪрж╛рж▓рж┐рзЯрзЗ ржирж┐рждрзЗ ржкрж╛рж░рзЗред ржПрж░ ржорзВрж▓ ржЙржжрзНржжрзЗрж╢рзНржп рж╣рж▓рзЛ system downtime ржХржорж╛ржирзЛред
тЬЕ Example (Redundancy):
ржПржХржЯрж┐ рж╕рж╛рж░рзНржнрж╛рж░рзЗ ржжрзБржЗржЯрж╛ ржкрж╛ржУржпрж╝рж╛рж░ рж╕рж╛ржкрзНрж▓рж╛ржЗ ржжрзЗржУрзЯрж╛ ржЖржЫрзЗред ржпржжрж┐ ржПржХржЯрж┐ ржирж╖рзНржЯ рж╣рзЯ, ржЕржирзНржпржЯрж┐ рж╕рж╛ржерзЗ рж╕рж╛ржерзЗ ржХрж╛ржЬ рж╢рзБрж░рзБ ржХрж░ржмрзЗред


Airline ржП multiple engines ржерж╛ржХрзЗред ржпржжрж┐ ржПржХржЯрж╛ engine fail ржХрж░рзЗ, plane ржЕржирзНржпржЯрж╛ ржжрж┐рзЯрзЗ ржЙрзЬрждрзЗ ржкрж╛рж░рзЗред



ЁЯФ╣ Replication (рж░рзЗржкрзНрж▓рж┐ржХрзЗрж╢ржи)
English:
 Replication means copying the same data/system to multiple locations so that it is available in more than one place. It is mainly for data availability, performance, and reliability.
Bangla:
 Replication ржорж╛ржирзЗ рж╣рж▓рзЛ ржПржХржЗ ржбрзЗржЯрж╛ ржмрж╛ рж╕рж┐рж╕рзНржЯрзЗржоржХрзЗ ржПржХрж╛ржзрж┐ржХ ржЬрж╛рзЯржЧрж╛рзЯ ржХржкрж┐ ржХрж░рзЗ рж░рж╛ржЦрж╛, ржпрж╛рждрзЗ ржбрзЗржЯрж╛ рж╕ржмрж╕ржорзЯ ржкрж╛ржУрзЯрж╛ ржпрж╛рзЯ ржПржмржВ ржжрзНрж░рзБржд access ржХрж░рж╛ ржпрж╛рзЯред ржПрж░ ржЙржжрзНржжрзЗрж╢рзНржп рж╣рж▓рзЛ data reliability + performance improvementред
тЬЕ Example (Replication):
Facebook ржПрж░ data ржЕржирзЗржХ data center-ржП copy ржХрж░рж╛ ржерж╛ржХрзЗред Dhaka server down рж╣рж▓рзЗржУ Singapore server ржерзЗржХрзЗ data ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржмрзЗред


A database uses master-slave replication: master database write ржХрж╛ржЬ ржХрж░рзЗ, ржЖрж░ slave database read ржХрж╛ржЬ ржХрж░рзЗред



ЁЯФ╣ Key Differences (ржорзВрж▓ ржкрж╛рж░рзНржержХрзНржп)
Aspect
Redundancy
Replication
Definition
Extra (backup) components to prevent system failure
Copying the same data/system to multiple locations
Purpose
Fault tolerance, high availability
Data reliability, load balancing, performance
Focus
Hardware/Infrastructure backup
Data/Information duplication
Example
Dual power supply in servers
Same database available in multiple servers
Failure Handling
Prevents total system crash
Ensures data is not lost and available everywhere


ЁЯФ╣ Notes (ржоржирзЗ рж░рж╛ржЦрж╛рж░ ржорждрзЛ ржкржпрж╝рзЗржирзНржЯ)
Redundancy = Backup Hardware/Component


Replication = Copy of Data/System


Redundancy focuses more on system availability,


Replication focuses more on data availability & performance.


ржЕржирзЗржХ рж╕ржорзЯ system-ржП ржжрзБржЯрзЛ ржПржХрж╕рж╛ржерзЗ ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯ (e.g., Cloud services тЖТ both redundancy + replication)ред

ЁЯСЙ рж╕рж╣ржЬ ржХрж░рзЗ ржмрж▓рж▓рзЗ:
Redundancy = ржПржХржЯрж╛ fail ржХрж░рж▓рзЗ backup ржЖржЫрзЗ


Replication = ржПржХржЗ data/system ржЕржирзЗржХ ржЬрж╛рзЯржЧрж╛рзЯ copy ржЖржЫрзЗ
        Load Balancer, ржПрж░ ржХрж╛ржЬ, ржЖрж░ Load Balancing Algorithms

 What is Load Balancer?
English:
 A Load Balancer is a device or software that distributes incoming network traffic across multiple servers. Its goal is to ensure no single server gets overloaded, so the system stays fast, reliable, and available.
Bangla:
 Load Balancer рж╣рж▓рзЛ ржПржоржи ржПржХржЯрж┐ рж╕рж┐рж╕рзНржЯрзЗржо (hardware ржмрж╛ software), ржпрзЗржЯрж╛ incoming traffic (ржЕржирзБрж░рзЛржз) ржЧрзБрж▓рзЛржХрзЗ ржПржХрж╛ржзрж┐ржХ server-ржПрж░ ржоржзрзНржпрзЗ ржнрж╛ржЧ ржХрж░рзЗ ржжрзЗрзЯред ржПрж░ ржлрж▓рзЗ ржХрзЛржирзЛ ржПржХ рж╕рж╛рж░рзНржнрж╛рж░ ржмрзЗрж╢рж┐ ржЪрж╛ржк (load) ржкрж╛рзЯ ржирж╛, ржЖрж░ ржкрзБрж░рзЛ рж╕рж┐рж╕рзНржЯрзЗржо smooth ржнрж╛ржмрзЗ ржЪрж▓рзЗред

ЁЯФ╣ How Load Balancer Works
English:
A user makes a request (e.g., visiting a website).


The request first goes to the Load Balancer.


The Load Balancer decides which server should handle the request using a specific algorithm.


The server processes the request and sends the response back through the Load Balancer.


Bangla:
User ржХрзЛржирзЛ request ржХрж░рж▓рзЗ (ржпрзЗржоржи: ржУрзЯрзЗржмрж╕рж╛ржЗржЯрзЗ ржврзБржХрж▓рзЛ)ред


Request ржкрзНрж░ржержорзЗ Load Balancer-ржПрж░ ржХрж╛ржЫрзЗ ржпрж╛рзЯред


Load Balancer ржирж┐рж░рзНржжрж┐рж╖рзНржЯ algorithm ржжрж┐рзЯрзЗ ржарж┐ржХ ржХрж░рзЗ ржХрзЛржи server ржПржЗ ржХрж╛ржЬ ржХрж░ржмрзЗред


Server ржХрж╛ржЬ рж╢рзЗрж╖ ржХрж░рзЗ ржЖржмрж╛рж░ Load Balancer ржПрж░ ржорж╛ржзрзНржпржорзЗ response ржкрж╛ржарж╛рзЯред


тЬЕ Example:
 ржзрж░рж╛ ржпрж╛ржХ рждрзЛржорж╛рж░ ржПржХржЯрж╛ e-commerce рж╕рж╛ржЗржЯ ржЖржЫрзЗ ржпрзЗржЦрж╛ржирзЗ рзкржЯрж╛ server ржЖржЫрзЗред ржПржХрж╕рж╛ржерзЗ рззрзж,рзжрзжрзж ржЬржи ржврзБржХрж▓рзЛред Load Balancer рж╕рзЗржЗ traffic ржХрзЗ рзкржЯрж╛ server-ржП ржнрж╛ржЧ ржХрж░рзЗ ржжрж┐ржмрзЗ, ржпрж╛рждрзЗ ржХрзЛржирзЛ server ржмрзЗрж╢рж┐ ржЪрж╛ржк ржирж╛ ржкрж╛рзЯред

Load Balancer = Server traffic police


Algorithms = Rule ржХрж┐ржнрж╛ржмрзЗ request ржнрж╛ржЧ рж╣ржмрзЗред





                             Load Balancing Algorithms

1я╕ПтГг Round Robin
English:
 Distributes requests one by one in order across all servers. After the last server, it starts again from the first.
 Bangla:
 Round Robin рж╣рж▓рзЛ рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ ржоржзрзНржпрзЗ request ржПржХрзЗрж░ ржкрж░ ржПржХ ржнрж╛ржЧ ржХрж░рж╛ред рж╢рзЗрж╖ рж╕рж╛рж░рзНржнрж╛рж░рзЗ ржЧрзЗрж▓рзЗ ржЖржмрж╛рж░ ржкрзНрж░ржержо рж╕рж╛рж░рзНржнрж╛рж░ ржерзЗржХрзЗ рж╢рзБрж░рзБ рж╣рзЯред
Example:
3ржЯрж┐ server: S1, S2, S3


Requests: R1, R2, R3, R4, R5


Distribution:


R1 тЖТ S1


R2 тЖТ S2


R3 тЖТ S3


R4 тЖТ S1


R5 тЖТ S2


Use Case:
Servers ржПржХржЗ ржзрж░ржирзЗрж░ ржПржмржВ capacity ржкрзНрж░рж╛ржпрж╝ рж╕ржорж╛ржиред



2я╕ПтГг Least Connections
English:
 Sends request to the server with the fewest active connections. Useful for servers with different response times.
 Bangla:
 ржпрзЗ рж╕рж╛рж░рзНржнрж╛рж░рзЗ рж╕ржмржЪрзЗржпрж╝рзЗ ржХржо active connection ржЖржЫрзЗ, ржирждрзБржи request рж╕рзЗржЦрж╛ржирзЗ ржпрж╛рзЯред
Example:
2ржЯрж┐ server: S1 (5 active), S2 (2 active)


New request тЖТ S2


Next request тЖТ whichever has fewer active connections


Use Case:
Servers capacity ржмрж╛ load ржнрж┐ржирзНржи рж╣рж▓рзЗред



3я╕ПтГг Weighted Round Robin
English:
 Each server is assigned a weight based on its capacity. Servers with higher weight get more requests.
 Bangla:
 ржкрзНрж░рждрж┐ржЯрж┐ рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ ржПржХржЯрж┐ weight ржерж╛ржХрзЗред capacity ржмрзЗрж╢рж┐ рж╣рж▓рзЗ ржмрзЗрж╢рж┐ request ржкрж╛ржмрзЗред
Example:
S1 weight = 3, S2 weight = 1


Requests: 4 requests


Distribution: S1, S1, S1, S2


Use Case:
Servers heterogeneous (ржнрж┐ржирзНржи ржХрзНрж╖ржорждрж╛рж░) рж╣рж▓рзЗред



4я╕ПтГг IP Hash
English:
 Assigns requests based on client IP address. The same client always goes to the same server.
 Bangla:
 Client ржПрж░ IP ржЕржирзБржпрж╛ржпрж╝рзА request рж╕рж╛рж░рзНржнрж╛рж░рзЗ ржпрж╛ржпрж╝ред ржПржХржЗ client рж╕ржмрж╕ржоржпрж╝ ржПржХржЗ рж╕рж╛рж░рзНржнрж╛рж░рзЗ ржпрж╛ржмрзЗред
Example:
Client IP: 192.168.1.10 тЖТ Hash тЖТ S2


Client IP: 192.168.1.20 тЖТ Hash тЖТ S1


Use Case:
Session persistence ржкрзНрж░рзЯрзЛржЬржи рж╣рж▓рзЗ (ржпрзЗржоржи online shopping)ред



5я╕ПтГг Least Response Time
English:
 Sends request to the server with fastest response time and lowest active connections.
 Bangla:
 ржпрзЗ рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ response time ржжрзНрж░рзБржд ржПржмржВ active connections ржХржо, рж╕рзЗржЦрж╛ржирзЗ request ржкрж╛ржарж╛ржирзЛ рж╣рзЯред
Example:
S1 response time = 50ms, 5 active


S2 response time = 30ms, 10 active


New request тЖТ S1 (even though S2 has faster CPU, active connections ржмрзЗрж╢рж┐)


Use Case:
Real-time applications, like video streaming or live gamesред



6я╕ПтГг Random
English:
 Sends requests to servers randomly, without following any rule.
 Bangla:
 Random ржнрж╛ржмрзЗ рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ ржоржзрзНржпрзЗ request ржкрж╛ржарж╛ржирзЛ рж╣рзЯред
Example:
Servers: S1, S2, S3


Requests: R1 тЖТ S2, R2 тЖТ S1, R3 тЖТ S3 (randomly)


Use Case:
Simple, small-scale systemsред



ЁЯФ╣ Key Notes
Round Robin тЖТ simple, same capacity serversред


Least Connections тЖТ dynamic load, servers may have different speedред


Weighted RR тЖТ heterogeneous serversред


IP Hash тЖТ session persistenceред


Least Response Time тЖТ performance-critical applicationsред


Random тЖТ simple, no state trackingред



ЁЯТб рж╕рж╣ржЬрзЗ ржоржирзЗ рж░рж╛ржЦрж╛рж░ ржЯрзНрж░рж┐ржХ:
Round Robin = orderly distribution


Least Connections = lightest server first


Weighted RR = strong server gets more


IP Hash = same client same server


Least Response Time = fastest available server


Random = luck based ЁЯШК


Caching:

English:
 Caching is the process of storing frequently accessed data temporarily so that future requests can be served faster.
The cache can be in memory, disk, or browser.


Main goal: Improve performance and reduce latency.


Bangla:
 Caching рж╣рж▓рзЛ ржПржоржи ржПржХржЯрж┐ ржкржжрзНржзрждрж┐ ржпрзЗржЦрж╛ржирзЗ ржкрзНрж░рж╛ржпрж╝ржЗ ржмрзНржпржмрж╣рзГржд рждржерзНржп рж╕рж╛ржоржпрж╝рж┐ржХржнрж╛ржмрзЗ рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рж╛ рж╣ржпрж╝, ржпрж╛рждрзЗ ржкрж░ржмрж░рзНрждрзАрждрзЗ рж╕рзЗржЗ рждржерзНржп ржжрзНрж░рзБржд ржкрж╛ржУрзЯрж╛ ржпрж╛рзЯред
Cache рж╣рждрзЗ ржкрж╛рж░рзЗ RAM, Disk ржмрж╛ Browserред


ржорзВрж▓ ржЙржжрзНржжрзЗрж╢рзНржп: Speed ржмрж╛ржбрж╝рж╛ржирзЛ ржПржмржВ delay ржХржорж╛ржирзЛред



ЁЯФ╣ How Caching Works
User requests data.


System checks if data is in cache.


If yes тЖТ fetch from cache (fast)


If no тЖТ fetch from main source, then store in cache for next time


Bangla:
User ржХрзЛржирзЛ data ржЪрж╛ржЗрж▓рзЛред


System ржжрзЗржЦрзЗ data cache-ржП ржЖржЫрзЗ ржХрж┐ржирж╛


ржЖржЫрзЗ тЖТ cache ржерзЗржХрзЗ ржкрж╛ржарж╛ржирзЛ (ржжрзНрж░рзБржд)


ржирзЗржЗ тЖТ main source ржерзЗржХрзЗ ржирж┐рзЯрзЗ ржЖрж╕рзЗ, ржкрж░рзЗрж░ ржмрж╛рж░ cache-ржП рж░рж╛ржЦрж╛ рж╣рзЯ



ЁЯФ╣ Types of Cache
Type
English Explanation
Bangla Explanation
Example
Browser Cache
Stores web page data locally in browser
ржмрзНрж░рж╛ржЙржЬрж╛рж░рзЗ ржУрзЯрзЗржм ржкрзЗржЬ рж╕ржВрж░ржХрзНрж╖ржг
You visit YouTube тЖТ next time faster load
Memory Cache (RAM)
Stores data in server memory for quick access
рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ RAM-ржП data рж░рж╛ржЦрж╛
Redis, Memcached
Disk Cache
Stores data on hard disk
рж╣рж╛рж░рзНржб ржбрж┐рж╕рзНржХрзЗ рж╕ржВрж░ржХрзНрж╖ржг
Browser cache images, OS page cache
Database Cache
Frequently accessed DB queries are cached
DB query ржлрж▓рж╛ржлрж▓ cache ржХрж░рж╛
SELECT query result cached in Redis


ЁЯФ╣ЁЯФ╣ Cache Eviction Techniques
English:
 Cache eviction is the process of removing old or unnecessary data from the cache when it is full so that new data can be stored.
Bangla:
 Cache eviction ржорж╛ржирзЗ рж╣рж▓рзЛ cache ржкрзВрж░рзНржг рж╣рж▓рзЗ ржкрзБрж░ржирзЛ ржмрж╛ ржЕржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝ data рж╕рж░рж╛ржирзЛ, ржпрж╛рждрзЗ ржирждрзБржи data cache-ржП рж░рж╛ржЦрж╛ ржпрж╛рзЯред

1я╕ПтГг LRU (Least Recently Used)
English:
 Removes the data that has not been used for the longest time.
Bangla:
 ржпрзЗ data рж╕ржмржЪрзЗрзЯрзЗ ржжрзАрж░рзНржШ рж╕ржорзЯ ржмрзНржпржмрж╣рж╛рж░ рж╣рзЯржирж┐, рж╕рзЗржЯрж┐ржХрзЗ cache ржерзЗржХрзЗ рж╕рж░рж╛ржирзЛ рж╣рзЯред
Example:
Cache size = 3, current cache = [A, B, C]


Access order: A тЖТ B тЖТ C тЖТ A тЖТ D


Evict тЖТ B (least recently used), cache becomes [C, A, D]


Use Case:
Web browser cache, CPU cache



2я╕ПтГг FIFO (First In First Out)
English:
 Removes the oldest data in the cache, i.e., the one that came first.
Bangla:
 ржпрзЗ data cache-ржП ржкрзНрж░ржержорзЗ ржПрж╕рзЗржЫрзЗ, рж╕рзЗржЯрж┐ ржкрзНрж░ржержо рж╕рж░рж╛ржирзЛ рж╣рзЯред
Example:
Cache size = 3, current cache = [A, B, C]


New data D тЖТ Evict A (first in), cache becomes [B, C, D]


Use Case:
Simple caching scenarios, queue-based systems



3я╕ПтГг LFU (Least Frequently Used)
English:
 Removes the data that has been used least frequently.
Bangla:
 ржпрзЗ data ржХржоржмрж╛рж░ ржмрзНржпржмрж╣рзГржд рж╣рзЯрзЗржЫрзЗ, рж╕рзЗржЯрж┐ cache ржерзЗржХрзЗ рж╕рж░рж╛ржирзЛ рж╣рзЯред
Example:
Cache = [A(5), B(2), C(3)] тЖТ numbers = usage frequency


New data D тЖТ Evict B (least frequency 2), cache = [A, C, D]


Use Case:
Applications where frequency matters, e.g., recommendation systems



4я╕ПтГг Random Replacement
English:
 Removes a randomly chosen data item from the cache.
Bangla:
 Cache ржерзЗржХрзЗ ржпрзЗржХрзЛржирзЛ random data рж╕рж░рж╛ржирзЛ рж╣рзЯред
Example:
Cache = [A, B, C] тЖТ New data D


Evict B randomly тЖТ cache = [A, C, D]


Use Case:
Simple or memory-constrained systems



5я╕ПтГг Time-based Eviction (TTL тАУ Time To Live)
English:
 Data is removed from cache after a fixed time period.
Bangla:
 Cache-ржП ржерж╛ржХрж╛ data ржирж┐рж░рзНржжрж┐рж╖рзНржЯ рж╕ржорзЯ ржкрж░рзЗ рж╕рж░рж╛ржирзЛ рж╣рзЯред
Example:
Cache TTL = 5 mins


Data X added at 10:00 тЖТ automatically evicted at 10:05


Use Case:
Session caches, web content caching



ЁЯФ╣ Notes
Eviction needed because cache size is limited


Choice of technique depends on:


Access patterns (recent vs frequent)


Performance requirements


Memory constraints


Often LRU + TTL combination is used in real-world systems



ЁЯТб рж╕рж╣ржЬрзЗ ржоржирзЗ рж░рж╛ржЦрж╛рж░ ржЙржкрж╛ржпрж╝:
LRU = Oldest unused


FIFO = First come, first out


LFU = Rarely used removed


Random = Lucky evict


TTL = Expire after time


ЁЯФ╣ Example
You visit a website тЖТ website images, HTML, JS files load тЖТ stored in browser cache


Next time you visit тЖТ page loads much faster because it fetches from cache, not server


Database example:


Query: SELECT * FROM users WHERE id=1
- First time тЖТ fetch from DB (slow)
- Next time тЖТ fetch from Redis cache (fast)


ЁЯФ╣ Notes
Cache = Speed Booster


Trade-off: Stale Data Risk тЖТ sometimes cached data is outdated


Often used in: Web apps, API calls, databases, OS, CPU



ЁЯТб рж╕рж╣ржЬрзЗ ржоржирзЗ рж░рж╛ржЦрж╛рж░ ржЙржкрж╛ржпрж╝:
 Cache = Short-term storage for faster access













